all:
	testing
	documentation

dictionary:
	autogen filename with language
	names, places -- skip k-best?

tokenizer:
	squish abbreviations? something like below?
	mwes = [
		('P', 'E'), # Politiets Efterretninger
		('d', 'M'), # denne Maaned
		('s', 'M'), # samme Maaned
		('f', 'M'), # forrige Maaned
	]
	mwe = nltk.tokenize.MWETokenizer(mwes, separator='.')
	words = mwe.tokenize(words)

hocr:
	improve segmentation/columnization
	* https://www.slideshare.net/MarkHollow/pycon-apac-2017-page-layout-analysis-of-19th-century-siamese-newspapers-using-python-and-opencv
	* https://www.danvk.org/2015/01/07/finding-blocks-of-text-in-an-image-using-python-opencv-and-numpy.html
	** https://github.com/danvk/oldnyc/blob/master/ocr/tess/crop_morphology.py
	** https://gist.github.com/luipillmann/d76eb4f4eea0320bb35dcd1b2a4575ee
	* https://github.com/glazzara/olena
	* https://github.com/phatn/lapdftext
	--build_pdf --images 1,2,3 --pdfname etc

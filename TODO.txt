tokenizer:
	dehyphenation: create containertoken to hold the partial tokens
	squish abbreviations? something like below?
	mwes = [
		('P', 'E'), # Politiets Efterretninger
		('d', 'M'), # denne Maaned
		('s', 'M'), # samme Maaned
		('f', 'M'), # forrige Maaned
	]
	mwe = nltk.tokenize.MWETokenizer(mwes, separator='.')
	words = mwe.tokenize(words)

heuristics:
	make make_settings interactive?

new build_pdf command:
	--images 1,2,3 --pdfname

corrected:
	apply edited binnedTokens to original for new corrected file
	new original option
Introduction
============

CorrectOCR is a tool to post-process OCR text in order to improve its quality, using a number of methods to minimize annotator work. It is based on code created by:

* Caitlin Richter (<ricca@seas.upenn.edu>)
* Matthew Wickes (<wickesm@seas.upenn.edu>)
* Deniz Beser (<dbeser@seas.upenn.edu>)
* Mitchell Marcus (<mitch@cis.upenn.edu>)

See their article _"Low-resource Post Processing of Noisy OCR Output for Historical Corpus Digitisation"_ (LREC-2018) for further details, it is available online: <http://www.lrec-conf.org/proceedings/lrec2018/pdf/971.pdf>

The original python 2.7 code (see `original`-tag in the repository) has been licensed under Creative Commons Attribution 4.0 ([CC-BY-4.0](https://creativecommons.org/licenses/by/4.0/), see also `license.txt` in the repository).

The code has subsequently been updated to Python 3 and further expanded by Mikkel Eide Eriksen (<mikkel.eriksen@gmail.com>) for the [Copenhagen City Archives](https://www.kbharkiv.dk/) (mainly structural changes, the algorithms are generally preserved as-is). Pull requests welcome!

Usage
========

Workflow
--------

Usage of CorrectOCR is divided into several successive tasks.

To train the software, one must first create or obtain set of matching original uncorrected files with corresponding known-correct "gold" files. Additionally, a dictionary of the target language is needed.

The pairs (original, gold) files are then used to create _k_ replacement candidates for each token (word) in a new given file. A number of heuristic decisions are configured based on whether a given token is found in the dictionary, are the candidates preferable to the original, etc. Finally, a CLI can be used by the annotator to select among the candidates, and a new corrected file is generated.

When a corrected file is satisfactory, it can be moved or copied to the gold directory and in turn be used to tune the HMM further, thus improving the _k_-best candidates for subsequent files.

Configuration
-------------

When invoked, CorrectOCR looks for a file named `CorrectOCR.ini` in the working directory. If found, it is loaded, and any entries will be considered defaults to their corresponding option. For example:

```INI
[configuration]
characterSet = ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz

[workspace]
correctedPath = corrected/
goldPath = gold/
originalPath = original/
trainingPath = training/
nheaderlines = 0

[resources]
correctionTrackingFile = resources/correction_tracking.json
dictionaryFile = resources/dictionary.txt
hmmParamsFile = resources/hmm_parameters.json
memoizedCorrectionsFile = resources/memoized_corrections.json
multiCharacterErrorFile = resources/multicharacter_errors.json
reportFile = resources/report.txt
heuristicSettingsFile = resources/settings.json
```

By default, CorrectOCR requires 4 subdirectories in the working directory, which will be used as the current `Workspace`:

* `original/` contains the original uncorrected files. If necessary, it can be configured with the `--originalPath` argument.
* `gold/` contains the known correct "gold" files. If necessary, it can be configured with the `--goldPath` argument.
* `training/` contains the various generated files used during training. If necessary, it can be configured with the `--trainingPath` argument.
* `corrected/` contains the corrected files generated by running the `correct` command. If necessary, it can be configured with the `--correctedPath` argument.

Corresponding files in _original_, _gold_, and _corrected_ are named identically. The generated files in `training/` have suffixes according to their kind.

If generated files exist, CorrectOCR will generally avoid doing redundant calculations. The `--force` switch overrides this, forcing CorrectOCR to create new files (after moving the existing ones out of the way). Alternately, one may delete a subset of the generated files to only recreate those.

The `Workspace` also has a `ResourceManager` (accessible via `.resources`) that handles access to the dictionary, HMM parameter files, etc.

Commands
--------

Commands and their arguments are called directly on the module, like so: `python -m CorrectOCR [command] [args...]`.

*  `build_dictionary` creates a dictionary.
   Input files can be either `.pdf`, `.txt`, or `.xml` (in [TEI format](https://en.wikipedia.org/wiki/Text_Encoding_Initiative)). They may be contained in `.zip`-files. 
   The `--corpusPath` option specifies a directory of files.
   The `--corpusFile` option specifies a list of paths and URLs to files. One such file for a dictionary covering 1800–1948 Danish is provided under `resources/`.
   It is strongly recommended to generate a large dictionary for best performance.

1. `align` aligns a pair of (original, gold) files in order to determine which characters and words were misread in the original and corrected in the gold.
	The `--fileid` option specifies a single pair of files to align.
	The `--all` option aligns all available pairs.

2. `build_model` uses the alignments to create parameters for the HMM.
	The `--smoothingParameter` option can be adjusted as needed.

3. `tokenize` tokenizes texts and uses the HMM to create _k_-best correction candidates.
	The `--fileid` option specifies which file to tokenize.
	The `--all` option tokenizes all available texts.

4. Heuristic decisions (see also [Heuristics](#heuristics) below): 

	* `make_report` generates a statistical report on whether originals/_k_-best equal are in the dictionary, etc. This report can then be inspected and annotated with the desired decision for each _bin_.

	* `make_settings` creates correction settings based on the annotated report.

5. `correct` uses the settings to sort the tokens into bins and makes automated decisions as configured.
	The `--fileid` option specifies which file to correct.
	The `--interactive` option runs an interactive correction CLI for the remaining undecided tokens (see [Correction Interface](#correction-interace) below).

Heuristics
----------

A given token and its _k_-best candidates are compared and checked with the dictionary. Based on this, it is matched with a _bin_.

|                            bin |  1  |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  |
|-------------------------------:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|                    _k_ = orig? |  T  |  T  |  T  |  F  |  F  |  F  |  F  |  F  |  F  |
|                  orig in dict? |  T  |  F  |  F  |  F  |  F  |  F  |  T  |  T  |  T  |
|          top _k_-best in dict? |  T  |  F  |  F  |  T  |  F  |  F  |  T  |  F  |  F  | 
| lower-ranked _k_-best in dict? |  –  |  F  |  T  |  –  |  F  |  T  |  –  |  F  |  T  | 

Each _bin_ must be assigned a setting that determines what decision is made:

* `o` / _original_: select the original token as correct.
* `k` / _kbest_: select the top _k_-best candidate as correct.
* `d` / _kdict_: select the first lower-ranked candidate that is in the dictionary.
* `a` / _annotator_: defer selection to annotator.

Once the report and settings are generated, it is not strictly necessary to update them every single time the model is updated. It is however a good idea to do it regularly as the corpus grows and more tokens become available for the statistics.

Correction Interface
--------------------

The annotator will be presented with the tokens that match a heuristic bin that was marked for annotation.

They may then enter a command. The commands reflect the above settings, with an additional `defer` command to defer decision to a later time.

Prefixing the entered text with an exclamation point causes it to be considered the corrected version of the token. For example, if the token is "Wagor" and no suitable candidate is available, the annotator may enter `!Wagon` to correct the word.

Corrections are memoized, so the file need not be corrected fully in one session. To finish a session and save corrections, use the `quit` command.

A `help` command is available in the interface.

Requirements
============

* Python >= 3.6

For package dependencies see [requirements.txt](requirements.txt)